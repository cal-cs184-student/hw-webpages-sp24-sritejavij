<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Pathtracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>



<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 3: Pathtracer</h1>
<h2 align="middle">Sriteja Vijapurapu</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>In this homework, I implemented various techniques for illuminating surfaces and objects for realistic lighting. Some methods include ray tracing, hemisphere sampling, and more. Note: AI tools were used to gain a deeper understanding of the underlying principles behind the concepts and how to approach implementation for a few tasks.</p>

<h2 align="middle">Section I: Ray Generation and Scene Intersection </h2>

<h3 align="middle">Ray Generation</h3>
	<p>For ray generation, I applied basic Monte Carlo integration over ns_aa randomly sampled rays passing through the neighborhood of the pixel. Rays were generated after normalizing and illuminated through the global illumination helper function. This works by essentially estimating the integral over a certain domain, which in this case is the immediate surroundings of the pixel, and provides accurate illumination.
	</p>
<h3 align="middle">Intersection</h3>
	<p>
		Ray-triangle intersection was performed by implementing the Möller-Trumbore algorithm. I first found the 2 edge vectors corresponding to a particular vertex, then computed the determinant with the edge and the normal to the edge and ray. This is useful in checking whether or not the ray is parallel to the triangle, in which case they will never intersect. Then, I computed barycentric coordinates, which, if outside of certain ranges depending on the vertex, show there are no intersections. The intersection point is found through the dot product of an edge and the corresponding barycentric coordinate. Finally, we double check the point is valid according to the timestep based on the bounds we have.
		Below are some images of files with normal shading.
	</p>
	
  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="task11.png" align="middle" width="600px"/>
        <figcaption align="middle">Spheres</figcaption>
      </td>
      <td>
        <img src="task12.png" align="middle" width="600px"/>
        <figcaption align="middle">Bunny</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="task13.png" align="middle" width="600px"/>
        <figcaption align="middle">Gems</figcaption>
      </td>
      <td>
        <img src="task14.png" align="middle" width="600px"/>
        <figcaption align="middle">Cow</figcaption>
      </td>
    </tr>
  </table>
</div>



<h2 align="middle">Section II: Bounding Volume Hierarchy</h2>

<h3 align="middle">BVH Consutrction</h3>
  <p>
	  For constructing the BVH tree, I went with a recursive approach, first checking the standard base case of whether or not we are at a leaf node. For the heuristic, along each axis, I computed the value of the left box’s surface area multiplied by the number of primitives on the left and added that with the value of the right box’s surface area multiplied by the number of primitives on the right side. Whichever was minimal was the axis I chose. I split into left and right boxes based on the average centroid position. I then recursed down the left and right subtrees based on the split from the heuristic. An interesting issue I ran into was pointer problems when performing the recursive call. The pointers to the vectors storing the primitives would get lost in the stack, causing my code to error. I asked ChatGPT how to fix this, and it recommended some C++ specific in-line function that addressed the problem without altering any dependencies. This was the partition function.
  </p>

  <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="task21.png" align="middle" width="600px"/>
        <figcaption align="middle">Max Planck</figcaption>
      </td>
      <td>
        <img src="task22.png" align="middle" width="600px"/>
        <figcaption align="middle">Beast</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="task23.png" align="middle" width="600px"/>
        <figcaption align="middle">Car</figcaption>
      </td>
      <td>
        <img src="task24.png" align="middle" width="600px"/>
        <figcaption align="middle">Building</figcaption>
      </td>
    </tr>
  </table>
</div>


<p>The rendering times of images such as Max Planck, the beast, and beetle, on average, took about 1.2 seconds. On the other hand, without BVH acceleration, the max planck image alone took nearly 2 minutes on my local machine. The building.dae file is another example, rendering almost instantly while taking minutes to render without the acceleration algorithm.
</p>




<h2 align="middle">Section III: Direct Illumination</h2>
	<p>The two main components of this section dealt with direct lighting through both uniform hemisphere sampling and light importance sampling. Uniform hemisphere sampling is a method by which we sample points evenly over a hemisphere surrounding a point on the surface. For each incoming radiance vector, we generate sample vectors that point in random directions over the hemisphere centered at the point, and the samples are chosen to be uniformly distributed. This helps with diffuse reflection since we can pseudo-simulate light scattering in many different directions upon hitting a surface. Importance sampling, on the other hand, can help reduce the noise created by uniform hemisphere sampling. More samples are generated here if those samples might contribute more to the light at a certain point, and less if not. So, we sample more frequently in directions towards light sources or along reflection vectors. The distribution of the samples, rather than using a uniform distribution, is the BSDF of the material. This allows for higher quality images with fewer generated samples. 
</p>
	
<div align="center">
  <table style="width:100%">
    <tr>
      <td align="center">
        <img src="task3hemisphere.png" width="400px"/>
        <figcaption>Uniform hemisphere sampling</figcaption>
      </td>
      <td align="center">
        <img src="task3importance.png" width="400px"/>
        <figcaption>Light importance sampling</figcaption>
      </td>
    </tr>
  </table>
</div>

	<p>In these images, we see how much less noise is created in the importance light sampling image and how much more crisp and detailed the image is. This makes sense considering how importance light sampling will effectively sample more in spots where noise could potentially be more prevalent and uniform samples the same rate everywhere.</p>
<p>Below are images of sampling based on the number of light rays we use.</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="task3l1.png" align="middle" width="400px"/>
        <figcaption align="middle">1 light ray</figcaption>
      </td>
      <td>
        <img src="task3l4.png" align="middle" width="400px"/>
        <figcaption align="middle">4 light rays</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="task3l16.png" align="middle" width="400px"/>
        <figcaption align="middle">16 light rays</figcaption>
      </td>
      <td>
        <img src="task3l64.png" align="middle" width="400px"/>
        <figcaption align="middle">64 light rays</figcaption>
      </td>
    </tr>
  </table>
</div>
	<p>In each of the images where we subsequently increase the number of light rays we render with, we also see how much more detailed the image becomes and how much less noise is being created while still maintaining the overall lighting effects even in the noisest, 1 light ray image. By the time we use the -l 64 flag, the picture is super clear with virtually no visible noise.</p>

<h2 align="middle">Section IV: Global Illumination</h2>
	<p>Indirect lighting, in short, is the way by which we illuminate objects with light that has already bounced off other surfaces. This can lead to color bleeding, which is a process by which the colors from some objects “leaks” into the lighting of other objects, and we see traces of that color in the other object. My code works by first calculating the hit point where the light ray intersects and finding the intersection distance as well as the outgoing ray. I first set L_out to the direct lighting output before updating to account for global illumination. To account for the possible no accumulation flag, we have a first conditional check to see whether or not we are at the maximum allowed depth or if the flag is true. Now, for actually adding the indirect lighting, I sample the BSDF as well as a pdf for the direction of the incoming direction of the bsdf. If it is significant (i.e. the probability isn’t 0 to avoid division by 0 and the bsdf has a nonzero magnitude) then I cast a new ray into the scene from the intersection point into the sampled direction. Then, with Russian roulette illumination, I check the conditions of whether or not we are at the maximum depth or if we terminate according to the coin_flip probability, and continue recursively calling the function to account for every next bounce. Now, L_out will contain the accumulated radiance from both direct and indirect lighting of a scene.
</p>
	
<div align="center">
  <table style="width:100%">
    <tr>
      <td align="center">
        <img src="task4direct.png" width="400px"/>
        <figcaption>Direct lighting</figcaption>
      </td>
      <td align="center">
        <img src="task4indirect.png" width="400px"/>
        <figcaption>Indirect lighting</figcaption>
      </td>
    </tr>
  </table>
</div>

	<p>Below are images depicting Russian roulette-based illumination with max ray depths ranging from 0 to 100. We notice that after just a maximum ray depth of 2, every change after is unnoticeable, and unnecessary in accurately portraying the scene.</p>
<div align="center">
  <table style="width:100%">
    <tr>
      <td align="center">
        <img src="task4m0russian.png" width="400px"/>
        <figcaption>Ray Depth = 0</figcaption>
      </td>
      <td align="center">
        <img src="task4m1russian.png" width="400px"/>
        <figcaption>Ray Depth = 1</figcaption>
      </td>
    </tr>
    <tr>
      <td align="center">
        <img src="task4m2russian.png" width="400px"/>
        <figcaption>Ray Depth = 2</figcaption>
      </td>
      <td align="center">
        <img src="task4m3russian.png" width="400px"/>
        <figcaption>Ray Depth = 3</figcaption>
      </td>
    </tr>
    <tr>
      <td align="center">
        <img src="task4m4russian.png" width="400px"/>
        <figcaption>Ray Depth = 4</figcaption>
      </td>
      <td align="center">
        <img src="task4m100russian.png" width="400px"/>
        <figcaption>Ray Depth = 100</figcaption>
      </td>
    </tr>
  </table>
</div>
	<p>Now, we look at noise difference in the spheres scene where we alter the sampling rate per pixel.</p>

	<div align="center">
  <table style="width:100%">
    <tr>
      <td align="center">
        <img src="task4s1.png" width="400px"/>
        <figcaption>s = 1</figcaption>
      </td>
      <td align="center">
        <img src="task4s2.png" width="400px"/>
        <figcaption>s = 2</figcaption>
      </td>
      <td align="center">
        <img src="task4s4.png" width="400px"/>
        <figcaption>s = 4</figcaption>
      </td>
      <td align="center">
        <img src="task4s8.png" width="400px"/>
        <figcaption>s = 8</figcaption>
      </td>
    </tr>
    <tr>
      <!-- Empty cells for spacing -->
      <td></td>
      <!-- This cell contains the first image of the second row and spans 1 column -->
      <td align="center">
        <img src="task4s16.png" width="400px"/>
        <figcaption>s = 16</figcaption>
      </td>
      <!-- This cell contains the second image of the second row and spans 1 column -->
      <td align="center">
        <img src="task4s64.png" width="400px"/>
        <figcaption>s = 64</figcaption>
      </td>
      <!-- This cell contains the third image of the second row and spans 1 column -->
      <td align="center">
        <img src="task4s1024.png" width="400px"/>
        <figcaption>s = 1024</figcaption>
      </td>
      <!-- Empty cells for spacing -->
      <td></td>
    </tr>
  </table>
</div>


<h2 align="middle">Section V: Adaptive Sampling</h2>

	<p>Adaptive sampling is a method by which we can vary the number of sample depending on where in the scene we are. Essentially, we are trying to figure out whether or not a pixel has converged based on the variance of the sample. We have a maximum tolerance level we multiply by the average of the samples’ mean, and if our condition is below this, we can safely say the pixel has converged. This leads to reduced noise, efficient calculations, and more. My code implements this by first collecting a predefined number of samples (ns_aa). Within this loop, I iterate through the batch size and collect samples. From each sample, I find the radiance generated from the rays and check the condition about the max tolerance. After the loop exits, I compute the radiance of the pixel based on the accumulated radiance from prior based on the tolerance heuristic.</p>

	
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="task3l1.png" align="middle" width="400px"/>
        <figcaption align="middle">Rendered image of a bunny</figcaption>
      </td>
      <td>
        <img src="task3l4.png" align="middle" width="400px"/>
        <figcaption align="middle">Sample heat map of the bunny</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="task3l16.png" align="middle" width="400px"/>
        <figcaption align="middle">Rendered image of a dragon</figcaption>
      </td>
      <td>
        <img src="task3l64.png" align="middle" width="400px"/>
        <figcaption align="middle">Sample heat map of the dragon</figcaption>
      </td>
    </tr>
  </table>
</div>
	

</body>
</html>
